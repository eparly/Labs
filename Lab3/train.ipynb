{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load CIFAR100 Dataset with fine labels\n",
    "transform = transforms.Compose([transforms.Resize(224), transforms.ToTensor(), transforms.Normalize((0.507, 0.487, 0.441), (0.267, 0.256, 0.276))])\n",
    "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Split train into training and validation\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_data, val_data = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Define models\n",
    "models_dict = {\n",
    "    # 'AlexNet': models.alexnet(),\n",
    "    'VGG16': models.vgg16(),\n",
    "    'ResNet18': models.resnet18()\n",
    "}\n",
    "\n",
    "# Modify the classifiers to output 100 classes for CIFAR100\n",
    "for model_name, model in models_dict.items():\n",
    "    if model_name == 'AlexNet' or model_name == 'VGG16':\n",
    "        model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, 100)\n",
    "    elif model_name == 'ResNet18':\n",
    "        model.fc = nn.Linear(model.fc.in_features, 100)\n",
    "\n",
    "# Training function\n",
    "def train(model, device, train_loader, val_loader, num_epochs, checkpoint_epochs, save_file=None, plot_file=None):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        n=0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            print(f\"batch {n} of {len(train_loader)}\")\n",
    "            n+=1\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_loss)\n",
    "        \n",
    "        print(datetime.datetime.now(), 'epoch:', epoch, 'train loss:', avg_loss)\n",
    "\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        val_avg_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(val_avg_loss)\n",
    "        \n",
    "        print(datetime.datetime.now(), 'epoch:', epoch, 'val loss:', val_avg_loss)\n",
    "\n",
    "        \n",
    "        if save_file != None:\n",
    "            torch.save(model.state_dict(), save_file)\n",
    "\n",
    "        if plot_file != None:\n",
    "            plt.figure(2, figsize=(12, 7))\n",
    "            plt.clf()\n",
    "            plt.plot(train_losses, label='train')\n",
    "            plt.plot(val_losses, label='val')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.ylabel('loss')\n",
    "            plt.legend(loc=1)\n",
    "            print('saving ', plot_file)\n",
    "            plt.savefig(plot_file)\n",
    "\n",
    "        # Save checkpoint if at a checkpoint epoch\n",
    "        if epoch + 1 in checkpoint_epochs:\n",
    "            torch.save(model.state_dict(), f\"{model_name}_epoch_{epoch+1}.pth\")\n",
    "\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "# Testing function\n",
    "def test(model, test_loader, top_k):\n",
    "    model.eval()\n",
    "    top1_errors, top5_errors = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, pred_top5 = outputs.topk(5, 1, largest=True, sorted=True)\n",
    "            top1_errors += (pred_top5[:, 0] != labels).sum().item()\n",
    "            top5_errors += (pred_top5 == labels.view(-1, 1)).sum().item()\n",
    "    \n",
    "    total_samples = len(test_loader.dataset)\n",
    "    top1_error_rate = top1_errors / total_samples\n",
    "    top5_error_rate = (total_samples - top5_errors) / total_samples\n",
    "    return top1_error_rate, top5_error_rate\n",
    "\n",
    "# Run the process for each model\n",
    "checkpoint_epochs = [5, 50]  # Modify '50' to the desired full convergence epoch count\n",
    "results = {}\n",
    "for model_name, model in models_dict.items():\n",
    "    print(f\"Training {model_name}\")\n",
    "    print('Using device: ', device)\n",
    "    model = model.to(device)\n",
    "    train_losses, val_losses = train(model, device, train_loader, val_loader, num_epochs=50, checkpoint_epochs=checkpoint_epochs, save_file=f\"{model_name}.pth\", plot_file=f\"{model_name}.png\")\n",
    "\n",
    "    # Test both checkpoints\n",
    "    for epoch in checkpoint_epochs:\n",
    "        model.load_state_dict(torch.load(f\"{model_name}_epoch_{epoch}.pth\"))\n",
    "        top1, top5 = test(model, test_loader, top_k=5)\n",
    "        results[f\"{model_name}_epoch_{epoch}\"] = {\"top1_error\": top1, \"top5_error\": top5}\n",
    "        print(f\"{model_name} Epoch {epoch} - Top-1 Error: {top1}, Top-5 Error: {top5}\")\n",
    "\n",
    "# Save or print final results\n",
    "print(\"Final results:\", results)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
