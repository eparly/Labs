{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ar7cVcDc8wXG",
        "outputId": "35b99325-1cca-450e-b1e4-2201f3e4f0e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training AlexNet\n",
            "Using device:  cuda\n",
            "batch 0 of 157\n",
            "batch 1 of 157\n",
            "batch 2 of 157\n",
            "batch 3 of 157\n",
            "batch 4 of 157\n",
            "batch 5 of 157\n",
            "batch 6 of 157\n",
            "batch 7 of 157\n",
            "batch 8 of 157\n",
            "batch 9 of 157\n",
            "batch 10 of 157\n",
            "batch 11 of 157\n",
            "batch 12 of 157\n",
            "batch 13 of 157\n",
            "batch 14 of 157\n",
            "batch 15 of 157\n",
            "batch 16 of 157\n",
            "batch 17 of 157\n",
            "batch 18 of 157\n",
            "batch 19 of 157\n",
            "batch 20 of 157\n",
            "batch 21 of 157\n",
            "batch 22 of 157\n",
            "batch 23 of 157\n",
            "batch 24 of 157\n",
            "batch 25 of 157\n",
            "batch 26 of 157\n",
            "batch 27 of 157\n",
            "batch 28 of 157\n",
            "batch 29 of 157\n",
            "batch 30 of 157\n",
            "batch 31 of 157\n",
            "batch 32 of 157\n",
            "batch 33 of 157\n",
            "batch 34 of 157\n",
            "batch 35 of 157\n",
            "batch 36 of 157\n",
            "batch 37 of 157\n",
            "batch 38 of 157\n",
            "batch 39 of 157\n",
            "batch 40 of 157\n",
            "batch 41 of 157\n",
            "batch 42 of 157\n",
            "batch 43 of 157\n",
            "batch 44 of 157\n",
            "batch 45 of 157\n",
            "batch 46 of 157\n",
            "batch 47 of 157\n",
            "batch 48 of 157\n",
            "batch 49 of 157\n",
            "batch 50 of 157\n",
            "batch 51 of 157\n",
            "batch 52 of 157\n",
            "batch 53 of 157\n",
            "batch 54 of 157\n",
            "batch 55 of 157\n",
            "batch 56 of 157\n",
            "batch 57 of 157\n",
            "batch 58 of 157\n",
            "batch 59 of 157\n",
            "batch 60 of 157\n",
            "batch 61 of 157\n",
            "batch 62 of 157\n",
            "batch 63 of 157\n",
            "batch 64 of 157\n",
            "batch 65 of 157\n",
            "batch 66 of 157\n",
            "batch 67 of 157\n",
            "batch 68 of 157\n",
            "batch 69 of 157\n",
            "batch 70 of 157\n",
            "batch 71 of 157\n",
            "batch 72 of 157\n",
            "batch 73 of 157\n",
            "batch 74 of 157\n",
            "batch 75 of 157\n",
            "batch 76 of 157\n",
            "batch 77 of 157\n",
            "batch 78 of 157\n",
            "batch 79 of 157\n",
            "batch 80 of 157\n",
            "batch 81 of 157\n",
            "batch 82 of 157\n",
            "batch 83 of 157\n",
            "batch 84 of 157\n",
            "batch 85 of 157\n",
            "batch 86 of 157\n",
            "batch 87 of 157\n",
            "batch 88 of 157\n",
            "batch 89 of 157\n",
            "batch 90 of 157\n",
            "batch 91 of 157\n",
            "batch 92 of 157\n",
            "batch 93 of 157\n",
            "batch 94 of 157\n",
            "batch 95 of 157\n",
            "batch 96 of 157\n",
            "batch 97 of 157\n",
            "batch 98 of 157\n",
            "batch 99 of 157\n",
            "batch 100 of 157\n",
            "batch 101 of 157\n",
            "batch 102 of 157\n",
            "batch 103 of 157\n",
            "batch 104 of 157\n",
            "batch 105 of 157\n",
            "batch 106 of 157\n",
            "batch 107 of 157\n",
            "batch 108 of 157\n",
            "batch 109 of 157\n",
            "batch 110 of 157\n",
            "batch 111 of 157\n",
            "batch 112 of 157\n",
            "batch 113 of 157\n",
            "batch 114 of 157\n",
            "batch 115 of 157\n",
            "batch 116 of 157\n",
            "batch 117 of 157\n",
            "batch 118 of 157\n",
            "batch 119 of 157\n",
            "batch 120 of 157\n",
            "batch 121 of 157\n",
            "batch 122 of 157\n",
            "batch 123 of 157\n",
            "batch 124 of 157\n",
            "batch 125 of 157\n",
            "batch 126 of 157\n",
            "batch 127 of 157\n",
            "batch 128 of 157\n",
            "batch 129 of 157\n",
            "batch 130 of 157\n",
            "batch 131 of 157\n",
            "batch 132 of 157\n",
            "batch 133 of 157\n",
            "batch 134 of 157\n",
            "batch 135 of 157\n",
            "batch 136 of 157\n",
            "batch 137 of 157\n",
            "batch 138 of 157\n",
            "batch 139 of 157\n",
            "batch 140 of 157\n",
            "batch 141 of 157\n",
            "batch 142 of 157\n",
            "batch 143 of 157\n",
            "batch 144 of 157\n",
            "batch 145 of 157\n",
            "batch 146 of 157\n",
            "batch 147 of 157\n",
            "batch 148 of 157\n",
            "batch 149 of 157\n",
            "batch 150 of 157\n",
            "batch 151 of 157\n",
            "batch 152 of 157\n",
            "batch 153 of 157\n",
            "batch 154 of 157\n",
            "batch 155 of 157\n",
            "batch 156 of 157\n",
            "2024-11-05 15:42:00.302797 epoch: 0 train loss: 4.243084104197799\n",
            "2024-11-05 15:42:22.671213 epoch: 0 val loss: 3.8757159650325774\n",
            "saving  AlexNet.png\n",
            "batch 0 of 157\n",
            "batch 1 of 157\n",
            "batch 2 of 157\n",
            "batch 3 of 157\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8b0d0507895e>\u001b[0m in \u001b[0;36m<cell line: 120>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using device: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{model_name}.pth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{model_name}.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;31m# Test both checkpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-8b0d0507895e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, val_loader, num_epochs, checkpoint_epochs, save_file, plot_file)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got inappropriate size arg: {size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2326\u001b[0m                 )\n\u001b[1;32m   2327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2328\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2330\u001b[0m     def reduce(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import datetime\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load CIFAR100 Dataset with fine labels\n",
        "transform = transforms.Compose([transforms.Resize(224), transforms.ToTensor(), transforms.Normalize((0.507, 0.487, 0.441), (0.267, 0.256, 0.276))])\n",
        "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Split train into training and validation\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_data, val_data = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=512, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=512, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Define models\n",
        "models_dict = {\n",
        "    'AlexNet': models.alexnet(),\n",
        "    'VGG16': models.vgg16(),\n",
        "    'ResNet18': models.resnet18()\n",
        "}\n",
        "\n",
        "# Modify the classifiers to output 100 classes for CIFAR100\n",
        "for model_name, model in models_dict.items():\n",
        "    if model_name == 'AlexNet' or model_name == 'VGG16':\n",
        "        model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, 100)\n",
        "    elif model_name == 'ResNet18':\n",
        "        model.fc = nn.Linear(model.fc.in_features, 100)\n",
        "\n",
        "# Training function\n",
        "def train(model, device, train_loader, val_loader, num_epochs, checkpoint_epochs, save_file=None, plot_file=None):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "    train_losses, val_losses = [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        n=0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            # print(f\"batch {n} of {len(train_loader)}\")\n",
        "            n+=1\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        train_losses.append(avg_loss)\n",
        "\n",
        "        print(datetime.datetime.now(), 'epoch:', epoch, 'train loss:', avg_loss)\n",
        "\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "        val_avg_loss = val_loss / len(val_loader)\n",
        "        val_losses.append(val_avg_loss)\n",
        "\n",
        "        print(datetime.datetime.now(), 'epoch:', epoch, 'val loss:', val_avg_loss)\n",
        "\n",
        "\n",
        "        if save_file != None:\n",
        "            torch.save(model.state_dict(), save_file)\n",
        "\n",
        "        if plot_file != None:\n",
        "            plt.figure(2, figsize=(12, 7))\n",
        "            plt.clf()\n",
        "            plt.plot(train_losses, label='train')\n",
        "            plt.plot(val_losses, label='val')\n",
        "            plt.xlabel('epoch')\n",
        "            plt.ylabel('loss')\n",
        "            plt.legend(loc=1)\n",
        "            print('saving ', plot_file)\n",
        "            plt.savefig(plot_file)\n",
        "\n",
        "        # Save checkpoint if at a checkpoint epoch\n",
        "        if epoch + 1 in checkpoint_epochs:\n",
        "            torch.save(model.state_dict(), f\"{model_name}_epoch_{epoch+1}.pth\")\n",
        "\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "# Testing function\n",
        "def test(model, test_loader, top_k):\n",
        "    model.eval()\n",
        "    top1_errors, top5_errors = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, pred_top5 = outputs.topk(5, 1, largest=True, sorted=True)\n",
        "            top1_errors += (pred_top5[:, 0] != labels).sum().item()\n",
        "            top5_errors += (pred_top5 == labels.view(-1, 1)).sum().item()\n",
        "\n",
        "    total_samples = len(test_loader.dataset)\n",
        "    top1_error_rate = top1_errors / total_samples\n",
        "    top5_error_rate = (total_samples - top5_errors) / total_samples\n",
        "    return top1_error_rate, top5_error_rate\n",
        "\n",
        "# Run the process for each model\n",
        "checkpoint_epochs = [5, 50]  # Modify '50' to the desired full convergence epoch count\n",
        "results = {}\n",
        "for model_name, model in models_dict.items():\n",
        "    print(f\"Training {model_name}\")\n",
        "    print('Using device: ', device)\n",
        "    model = model.to(device)\n",
        "    train_losses, val_losses = train(model, device, train_loader, val_loader, num_epochs=50, checkpoint_epochs=checkpoint_epochs, save_file=f\"{model_name}.pth\", plot_file=f\"{model_name}.png\")\n",
        "\n",
        "    # Test both checkpoints\n",
        "    for epoch in checkpoint_epochs:\n",
        "        model.load_state_dict(torch.load(f\"{model_name}_epoch_{epoch}.pth\"))\n",
        "        top1, top5 = test(model, test_loader, top_k=5)\n",
        "        results[f\"{model_name}_epoch_{epoch}\"] = {\"top1_error\": top1, \"top5_error\": top5}\n",
        "        print(f\"{model_name} Epoch {epoch} - Top-1 Error: {top1}, Top-5 Error: {top5}\")\n",
        "\n",
        "# Save or print final results\n",
        "print(\"Final results:\", results)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}