{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar7cVcDc8wXG",
        "outputId": "8f0d9a5a-8275-4e39-dd91-5a3bfd9caa56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training ResNet18\n",
            "Using device:  cuda\n",
            "batch 0 of 98\n",
            "batch 25 of 98\n",
            "batch 50 of 98\n",
            "batch 75 of 98\n",
            "2024-11-19 04:51:54.018264 epoch: 0 train loss: 4.106307316799553\n",
            "2024-11-19 04:51:56.613604 epoch: 0 val loss: 3.6579513430595396\n",
            "saving  ResNet18_Scheduled.png\n",
            "batch 0 of 98\n",
            "batch 25 of 98\n",
            "batch 50 of 98\n",
            "batch 75 of 98\n",
            "2024-11-19 04:52:18.113860 epoch: 1 train loss: 3.321085119734005\n",
            "2024-11-19 04:52:20.682251 epoch: 1 val loss: 3.3334126353263853\n",
            "saving  ResNet18_Scheduled.png\n",
            "batch 0 of 98\n",
            "batch 25 of 98\n",
            "batch 50 of 98\n",
            "batch 75 of 98\n",
            "2024-11-19 04:52:41.973475 epoch: 2 train loss: 2.8907539528243396\n",
            "2024-11-19 04:52:44.504077 epoch: 2 val loss: 3.1717507243156433\n",
            "saving  ResNet18_Scheduled.png\n",
            "batch 0 of 98\n",
            "batch 25 of 98\n",
            "batch 50 of 98\n",
            "batch 75 of 98\n",
            "2024-11-19 04:53:06.056871 epoch: 3 train loss: 2.511044344123529\n",
            "2024-11-19 04:53:08.635585 epoch: 3 val loss: 3.0851183891296388\n",
            "saving  ResNet18_Scheduled.png\n",
            "batch 0 of 98\n",
            "batch 25 of 98\n",
            "batch 50 of 98\n",
            "batch 75 of 98\n",
            "2024-11-19 04:53:30.073582 epoch: 4 train loss: 2.136835368312135\n",
            "2024-11-19 04:53:32.627979 epoch: 4 val loss: 3.053997242450714\n",
            "saving  ResNet18_Scheduled.png\n",
            "batch 0 of 98\n",
            "batch 25 of 98\n",
            "batch 50 of 98\n",
            "batch 75 of 98\n",
            "2024-11-19 04:53:54.304883 epoch: 5 train loss: 1.7523432045566791\n",
            "2024-11-19 04:53:56.786166 epoch: 5 val loss: 3.0719073891639708\n",
            "saving  ResNet18_Scheduled.png\n",
            "batch 0 of 98\n",
            "batch 25 of 98\n",
            "batch 50 of 98\n",
            "batch 75 of 98\n",
            "2024-11-19 04:54:18.321231 epoch: 6 train loss: 1.3587003727348483\n",
            "2024-11-19 04:54:20.883467 epoch: 6 val loss: 3.1145718336105346\n",
            "saving  ResNet18_Scheduled.png\n",
            "batch 0 of 98\n",
            "batch 25 of 98\n",
            "batch 50 of 98\n",
            "batch 75 of 98\n",
            "2024-11-19 04:54:42.386313 epoch: 7 train loss: 0.9836517797440899\n",
            "2024-11-19 04:54:44.902503 epoch: 7 val loss: 3.1936906576156616\n",
            "saving  ResNet18_Scheduled.png\n",
            "batch 0 of 98\n",
            "batch 25 of 98\n",
            "batch 50 of 98\n",
            "batch 75 of 98\n",
            "2024-11-19 04:55:06.681086 epoch: 8 train loss: 0.6519609227472422\n",
            "2024-11-19 04:55:09.318919 epoch: 8 val loss: 3.265143620967865\n",
            "saving  ResNet18_Scheduled.png\n",
            "batch 0 of 98\n",
            "batch 25 of 98\n",
            "batch 50 of 98\n",
            "batch 75 of 98\n",
            "2024-11-19 04:55:31.002489 epoch: 9 train loss: 0.39982094539671525\n",
            "2024-11-19 04:55:33.696008 epoch: 9 val loss: 3.3452989220619203\n",
            "saving  ResNet18_Scheduled.png\n",
            "batch 0 of 98\n",
            "batch 25 of 98\n",
            "batch 50 of 98\n",
            "batch 75 of 98\n",
            "2024-11-19 04:55:55.324192 epoch: 10 train loss: 0.2323650872829009\n",
            "2024-11-19 04:55:57.805850 epoch: 10 val loss: 3.38974244594574\n",
            "saving  ResNet18_Scheduled.png\n",
            "batch 0 of 98\n",
            "batch 25 of 98\n",
            "batch 50 of 98\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load CIFAR100 Dataset with fine labels\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.507, 0.487, 0.441), (0.267, 0.256, 0.276))])\n",
        "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Split train into training and validation\n",
        "# train_size = int(0.8 * len(train_dataset))\n",
        "# val_size = len(train_dataset) - train_size\n",
        "# train_data, val_data = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Define models\n",
        "models_dict = {\n",
        "    # 'AlexNet': models.alexnet(weights=None, num_classes=100),\n",
        "    # 'VGG16': models.vgg16(weights=None, num_classes=100),\n",
        "    'ResNet18': models.resnet18(weights=None, num_classes=100)\n",
        "}\n",
        "\n",
        "# Modify the classifiers to output 100 classes for CIFAR100\n",
        "# for model_name, model in models_dict.items():\n",
        "#     if model_name == 'AlexNet' or model_name == 'VGG16':\n",
        "#       print('fitting last layer to 100')\n",
        "#       model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, 100)\n",
        "#     elif model_name == 'ResNet18':\n",
        "#       model.fc = nn.Linear(model.fc.in_features, 100)\n",
        "\n",
        "# Training function\n",
        "def train(model, device, train_loader, val_loader, num_epochs, checkpoint_epochs, save_file=None, plot_file=None):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0005)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
        "    train_losses, val_losses = [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        n=0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if(n%25 == 0):\n",
        "              print(f\"batch {n} of {len(train_loader)}\")\n",
        "            n+=1\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        scheduler.step(running_loss)\n",
        "        train_losses.append(avg_loss)\n",
        "\n",
        "        print(datetime.datetime.now(), 'epoch:', epoch, 'train loss:', avg_loss)\n",
        "\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "        val_avg_loss = val_loss / len(val_loader)\n",
        "        val_losses.append(val_avg_loss)\n",
        "\n",
        "        print(datetime.datetime.now(), 'epoch:', epoch, 'val loss:', val_avg_loss)\n",
        "\n",
        "\n",
        "        if save_file != None:\n",
        "            torch.save(model.state_dict(), save_file)\n",
        "\n",
        "        if plot_file != None:\n",
        "            plt.figure(2, figsize=(12, 7))\n",
        "            plt.clf()\n",
        "            plt.plot(train_losses, label='train')\n",
        "            plt.plot(val_losses, label='val')\n",
        "            plt.xlabel('epoch')\n",
        "            plt.ylabel('loss')\n",
        "            plt.legend(loc=1)\n",
        "            print('saving ', plot_file)\n",
        "            plt.savefig(plot_file)\n",
        "\n",
        "        # Save checkpoint if at a checkpoint epoch\n",
        "        if epoch + 1 in checkpoint_epochs:\n",
        "            torch.save(model.state_dict(), f\"{model_name}_epoch_{epoch+1}.pth\")\n",
        "\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "# Testing function\n",
        "def test(model, test_loader, top_k):\n",
        "    model.eval()\n",
        "    top1_errors, top5_errors = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, pred_top5 = outputs.topk(5, 1, largest=True, sorted=True)\n",
        "            top1_errors += (pred_top5[:, 0] != labels).sum().item()\n",
        "            top5_errors += (pred_top5 == labels.view(-1, 1)).sum().item()\n",
        "\n",
        "    total_samples = len(test_loader.dataset)\n",
        "    top1_error_rate = top1_errors / total_samples\n",
        "    top5_error_rate = (total_samples - top5_errors) / total_samples\n",
        "    return top1_error_rate, top5_error_rate\n",
        "\n",
        "# Run the process for each model\n",
        "checkpoint_epochs = [5, 50]  # Modify '50' to the desired full convergence epoch count\n",
        "results = {}\n",
        "for model_name, model in models_dict.items():\n",
        "    print(f\"Training {model_name}\")\n",
        "    print('Using device: ', device)\n",
        "    model = model.to(device)\n",
        "    train_losses, val_losses = train(model, device, train_loader, val_loader, num_epochs=50, checkpoint_epochs=checkpoint_epochs, save_file=f\"{model_name}_Scheduled.pth\", plot_file=f\"{model_name}_Scheduled.png\")\n",
        "\n",
        "    # Test both checkpoints\n",
        "    for epoch in checkpoint_epochs:\n",
        "        model.load_state_dict(torch.load(f\"{model_name}_epoch_{epoch}.pth\"))\n",
        "        top1, top5 = test(model, test_loader, top_k=5)\n",
        "        results[f\"{model_name}_epoch_{epoch}\"] = {\"top1_error\": top1, \"top5_error\": top5}\n",
        "        print(f\"{model_name} Epoch {epoch} - Top-1 Error: {top1}, Top-5 Error: {top5}\")\n",
        "\n",
        "# Save or print final results\n",
        "print(\"Final results:\", results)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}