{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "Ar7cVcDc8wXG",
        "outputId": "09918ddb-9eef-4bc0-a70a-2fac87b26249"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'torchvision.transforms' has no attribute 'resize'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-27cb8d7c4dba>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Load CIFAR100 Dataset with fine labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m227\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.507\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.487\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.441\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.267\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.276\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR100\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR100\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torchvision.transforms' has no attribute 'resize'"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load CIFAR100 Dataset with fine labels\n",
        "transform = transforms.Compose([transforms.Resize(227), transforms.ToTensor(), transforms.Normalize((0.507, 0.487, 0.441), (0.267, 0.256, 0.276))])\n",
        "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Split train into training and validation\n",
        "# train_size = int(0.8 * len(train_dataset))\n",
        "# val_size = len(train_dataset) - train_size\n",
        "# train_data, val_data = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Define models\n",
        "models_dict = {\n",
        "    'AlexNet': models.alexnet(weights=None, num_classes=100),\n",
        "    # 'VGG16': models.vgg16(),\n",
        "    # 'ResNet18': models.resnet18(weights=None, num_classes=100)\n",
        "}\n",
        "\n",
        "# Modify the classifiers to output 100 classes for CIFAR100\n",
        "# for model_name, model in models_dict.items():\n",
        "#     if model_name == 'AlexNet' or model_name == 'VGG16':\n",
        "#       print('fitting last layer to 100')\n",
        "#       model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, 100)\n",
        "#     elif model_name == 'ResNet18':\n",
        "#       model.fc = nn.Linear(model.fc.in_features, 100)\n",
        "\n",
        "# Training function\n",
        "def train(model, device, train_loader, val_loader, num_epochs, checkpoint_epochs, save_file=None, plot_file=None):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
        "    train_losses, val_losses = [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        n=0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if(n%25 == 0):\n",
        "              print(f\"batch {n} of {len(train_loader)}\")\n",
        "            n+=1\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        scheduler.step(running_loss)\n",
        "        train_losses.append(avg_loss)\n",
        "\n",
        "        print(datetime.datetime.now(), 'epoch:', epoch, 'train loss:', avg_loss)\n",
        "\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "        val_avg_loss = val_loss / len(val_loader)\n",
        "        val_losses.append(val_avg_loss)\n",
        "\n",
        "        print(datetime.datetime.now(), 'epoch:', epoch, 'val loss:', val_avg_loss)\n",
        "\n",
        "\n",
        "        if save_file != None:\n",
        "            torch.save(model.state_dict(), save_file)\n",
        "\n",
        "        if plot_file != None:\n",
        "            plt.figure(2, figsize=(12, 7))\n",
        "            plt.clf()\n",
        "            plt.plot(train_losses, label='train')\n",
        "            plt.plot(val_losses, label='val')\n",
        "            plt.xlabel('epoch')\n",
        "            plt.ylabel('loss')\n",
        "            plt.legend(loc=1)\n",
        "            print('saving ', plot_file)\n",
        "            plt.savefig(plot_file)\n",
        "\n",
        "        # Save checkpoint if at a checkpoint epoch\n",
        "        if epoch + 1 in checkpoint_epochs:\n",
        "            torch.save(model.state_dict(), f\"{model_name}_epoch_{epoch+1}.pth\")\n",
        "\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "# Testing function\n",
        "def test(model, test_loader, top_k):\n",
        "    model.eval()\n",
        "    top1_errors, top5_errors = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, pred_top5 = outputs.topk(5, 1, largest=True, sorted=True)\n",
        "            top1_errors += (pred_top5[:, 0] != labels).sum().item()\n",
        "            top5_errors += (pred_top5 == labels.view(-1, 1)).sum().item()\n",
        "\n",
        "    total_samples = len(test_loader.dataset)\n",
        "    top1_error_rate = top1_errors / total_samples\n",
        "    top5_error_rate = (total_samples - top5_errors) / total_samples\n",
        "    return top1_error_rate, top5_error_rate\n",
        "\n",
        "# Run the process for each model\n",
        "checkpoint_epochs = [5, 50]  # Modify '50' to the desired full convergence epoch count\n",
        "results = {}\n",
        "for model_name, model in models_dict.items():\n",
        "    print(f\"Training {model_name}\")\n",
        "    print('Using device: ', device)\n",
        "    model = model.to(device)\n",
        "    train_losses, val_losses = train(model, device, train_loader, val_loader, num_epochs=50, checkpoint_epochs=checkpoint_epochs, save_file=f\"{model_name}_Scheduled.pth\", plot_file=f\"{model_name}_Scheduled.png\")\n",
        "\n",
        "    # Test both checkpoints\n",
        "    for epoch in checkpoint_epochs:\n",
        "        model.load_state_dict(torch.load(f\"{model_name}_epoch_{epoch}.pth\"))\n",
        "        top1, top5 = test(model, test_loader, top_k=5)\n",
        "        results[f\"{model_name}_epoch_{epoch}\"] = {\"top1_error\": top1, \"top5_error\": top5}\n",
        "        print(f\"{model_name} Epoch {epoch} - Top-1 Error: {top1}, Top-5 Error: {top5}\")\n",
        "\n",
        "# Save or print final results\n",
        "print(\"Final results:\", results)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}