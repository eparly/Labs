{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ar7cVcDc8wXG",
        "outputId": "f0cc72be-c1db-42fb-9e36-cf604669c0c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training AlexNet\n",
            "Using device:  cuda\n",
            "Gradient of features.0.weight: 0.0031898499000817537\n",
            "Gradient of features.0.bias: 0.0001423712237738073\n",
            "Gradient of features.3.weight: 0.006662086583673954\n",
            "Gradient of features.3.bias: 0.00032897229539230466\n",
            "Gradient of features.6.weight: 0.0070913368836045265\n",
            "Gradient of features.6.bias: 0.0006816494860686362\n",
            "Gradient of features.8.weight: 0.009998833760619164\n",
            "Gradient of features.8.bias: 0.0017270795069634914\n",
            "Gradient of features.10.weight: 0.00865924172103405\n",
            "Gradient of features.10.bias: 0.0049166083335876465\n",
            "Gradient of classifier.1.weight: 0.02322992868721485\n",
            "Gradient of classifier.1.bias: 0.007175469771027565\n",
            "Gradient of classifier.4.weight: 0.016261273995041847\n",
            "Gradient of classifier.4.bias: 0.012071619741618633\n",
            "Gradient of classifier.6.weight: 0.019864657893776894\n",
            "Gradient of classifier.6.bias: 0.028430651873350143\n",
            "Parameter features.0.weight after step: 4.614903450012207\n",
            "Parameter features.0.bias after step: 0.2578955292701721\n",
            "Parameter features.3.weight after step: 7.995477199554443\n",
            "Parameter features.3.bias after step: 0.19868391752243042\n",
            "Parameter features.6.weight after step: 11.308544158935547\n",
            "Parameter features.6.bias after step: 0.2677425444126129\n",
            "Parameter features.8.weight after step: 9.24176025390625\n",
            "Parameter features.8.bias after step: 0.14991188049316406\n",
            "Parameter features.10.weight after step: 9.230460166931152\n",
            "Parameter features.10.bias after step: 0.1963670402765274\n",
            "Parameter classifier.1.weight after step: 36.956138610839844\n",
            "Parameter classifier.1.bias after step: 0.38285598158836365\n",
            "Parameter classifier.4.weight after step: 36.94754409790039\n",
            "Parameter classifier.4.bias after step: 0.5774891376495361\n",
            "Parameter classifier.6.weight after step: 5.776337146759033\n",
            "Parameter classifier.6.bias after step: 0.08521277457475662\n",
            "batch 0 of 49\n",
            "Gradient of features.0.weight: 0.0033091488294303417\n",
            "Gradient of features.0.bias: 0.0001696307008387521\n",
            "Gradient of features.3.weight: 0.007349824532866478\n",
            "Gradient of features.3.bias: 0.00036947440821677446\n",
            "Gradient of features.6.weight: 0.008251447230577469\n",
            "Gradient of features.6.bias: 0.0008122468716464937\n",
            "Gradient of features.8.weight: 0.012176820077002048\n",
            "Gradient of features.8.bias: 0.0023009618744254112\n",
            "Gradient of features.10.weight: 0.009538685902953148\n",
            "Gradient of features.10.bias: 0.005613027606159449\n",
            "Gradient of classifier.1.weight: 0.02347227744758129\n",
            "Gradient of classifier.1.bias: 0.007592119742184877\n",
            "Gradient of classifier.4.weight: 0.01646353490650654\n",
            "Gradient of classifier.4.bias: 0.01378696970641613\n",
            "Gradient of classifier.6.weight: 0.02163582108914852\n",
            "Gradient of classifier.6.bias: 0.0343223437666893\n",
            "Parameter features.0.weight after step: 4.614903450012207\n",
            "Parameter features.0.bias after step: 0.25789549946784973\n",
            "Parameter features.3.weight after step: 7.995477199554443\n",
            "Parameter features.3.bias after step: 0.19868390262126923\n",
            "Parameter features.6.weight after step: 11.308544158935547\n",
            "Parameter features.6.bias after step: 0.26774248480796814\n",
            "Parameter features.8.weight after step: 9.24176025390625\n",
            "Parameter features.8.bias after step: 0.1499118059873581\n",
            "Parameter features.10.weight after step: 9.230460166931152\n",
            "Parameter features.10.bias after step: 0.19636699557304382\n",
            "Parameter classifier.1.weight after step: 36.956138610839844\n",
            "Parameter classifier.1.bias after step: 0.3828560411930084\n",
            "Parameter classifier.4.weight after step: 36.94754409790039\n",
            "Parameter classifier.4.bias after step: 0.5774889588356018\n",
            "Parameter classifier.6.weight after step: 5.776337146759033\n",
            "Parameter classifier.6.bias after step: 0.08521188795566559\n",
            "Gradient of features.0.weight: 0.00275759631767869\n",
            "Gradient of features.0.bias: 0.00015310186427086592\n",
            "Gradient of features.3.weight: 0.007325861603021622\n",
            "Gradient of features.3.bias: 0.00039248887333087623\n",
            "Gradient of features.6.weight: 0.00833078008145094\n",
            "Gradient of features.6.bias: 0.0007920616189949214\n",
            "Gradient of features.8.weight: 0.011146154254674911\n",
            "Gradient of features.8.bias: 0.0019741530995815992\n",
            "Gradient of features.10.weight: 0.009042327292263508\n",
            "Gradient of features.10.bias: 0.004890145268291235\n",
            "Gradient of classifier.1.weight: 0.023592879995703697\n",
            "Gradient of classifier.1.bias: 0.007485129404813051\n",
            "Gradient of classifier.4.weight: 0.016366418451070786\n",
            "Gradient of classifier.4.bias: 0.012718074023723602\n",
            "Gradient of classifier.6.weight: 0.02051566168665886\n",
            "Gradient of classifier.6.bias: 0.030563466250896454\n",
            "Parameter features.0.weight after step: 4.614903450012207\n",
            "Parameter features.0.bias after step: 0.25789549946784973\n",
            "Parameter features.3.weight after step: 7.995477199554443\n",
            "Parameter features.3.bias after step: 0.19868390262126923\n",
            "Parameter features.6.weight after step: 11.308544158935547\n",
            "Parameter features.6.bias after step: 0.26774245500564575\n",
            "Parameter features.8.weight after step: 9.24176025390625\n",
            "Parameter features.8.bias after step: 0.14991165697574615\n",
            "Parameter features.10.weight after step: 9.230460166931152\n",
            "Parameter features.10.bias after step: 0.1963670700788498\n",
            "Parameter classifier.1.weight after step: 36.956138610839844\n",
            "Parameter classifier.1.bias after step: 0.3828561305999756\n",
            "Parameter classifier.4.weight after step: 36.94754409790039\n",
            "Parameter classifier.4.bias after step: 0.5774887204170227\n",
            "Parameter classifier.6.weight after step: 5.776336669921875\n",
            "Parameter classifier.6.bias after step: 0.08521433174610138\n",
            "Gradient of features.0.weight: 0.0029011406004428864\n",
            "Gradient of features.0.bias: 0.00014073784404899925\n",
            "Gradient of features.3.weight: 0.006694006733596325\n",
            "Gradient of features.3.bias: 0.0003622673393692821\n",
            "Gradient of features.6.weight: 0.007990633137524128\n",
            "Gradient of features.6.bias: 0.000821359979454428\n",
            "Gradient of features.8.weight: 0.010625907219946384\n",
            "Gradient of features.8.bias: 0.0019670622423291206\n",
            "Gradient of features.10.weight: 0.008778035640716553\n",
            "Gradient of features.10.bias: 0.00493584293872118\n",
            "Gradient of classifier.1.weight: 0.023160889744758606\n",
            "Gradient of classifier.1.bias: 0.007187969982624054\n",
            "Gradient of classifier.4.weight: 0.016031337901949883\n",
            "Gradient of classifier.4.bias: 0.011837422847747803\n",
            "Gradient of classifier.6.weight: 0.019561151042580605\n",
            "Gradient of classifier.6.bias: 0.028313085436820984\n",
            "Parameter features.0.weight after step: 4.614903450012207\n",
            "Parameter features.0.bias after step: 0.25789549946784973\n",
            "Parameter features.3.weight after step: 7.995477676391602\n",
            "Parameter features.3.bias after step: 0.19868391752243042\n",
            "Parameter features.6.weight after step: 11.308544158935547\n",
            "Parameter features.6.bias after step: 0.267742395401001\n",
            "Parameter features.8.weight after step: 9.24176025390625\n",
            "Parameter features.8.bias after step: 0.14991158246994019\n",
            "Parameter features.10.weight after step: 9.230460166931152\n",
            "Parameter features.10.bias after step: 0.19636742770671844\n",
            "Parameter classifier.1.weight after step: 36.956138610839844\n",
            "Parameter classifier.1.bias after step: 0.382856160402298\n",
            "Parameter classifier.4.weight after step: 36.94754409790039\n",
            "Parameter classifier.4.bias after step: 0.5774886012077332\n",
            "Parameter classifier.6.weight after step: 5.776336669921875\n",
            "Parameter classifier.6.bias after step: 0.08521740138530731\n",
            "Gradient of features.0.weight: 0.003274878254160285\n",
            "Gradient of features.0.bias: 0.00017834734171628952\n",
            "Gradient of features.3.weight: 0.007203755900263786\n",
            "Gradient of features.3.bias: 0.00035830066190101206\n",
            "Gradient of features.6.weight: 0.008273131214082241\n",
            "Gradient of features.6.bias: 0.000858062063343823\n",
            "Gradient of features.8.weight: 0.011176079511642456\n",
            "Gradient of features.8.bias: 0.0020977130625396967\n",
            "Gradient of features.10.weight: 0.008999747224152088\n",
            "Gradient of features.10.bias: 0.005071175284683704\n",
            "Gradient of classifier.1.weight: 0.023597560822963715\n",
            "Gradient of classifier.1.bias: 0.0075186570174992085\n",
            "Gradient of classifier.4.weight: 0.016637278720736504\n",
            "Gradient of classifier.4.bias: 0.013563158921897411\n",
            "Gradient of classifier.6.weight: 0.020788975059986115\n",
            "Gradient of classifier.6.bias: 0.0313686765730381\n",
            "Parameter features.0.weight after step: 4.614903450012207\n",
            "Parameter features.0.bias after step: 0.2578955292701721\n",
            "Parameter features.3.weight after step: 7.995477676391602\n",
            "Parameter features.3.bias after step: 0.1986839324235916\n",
            "Parameter features.6.weight after step: 11.308544158935547\n",
            "Parameter features.6.bias after step: 0.2677423357963562\n",
            "Parameter features.8.weight after step: 9.24176025390625\n",
            "Parameter features.8.bias after step: 0.14991150796413422\n",
            "Parameter features.10.weight after step: 9.230460166931152\n",
            "Parameter features.10.bias after step: 0.19636772572994232\n",
            "Parameter classifier.1.weight after step: 36.956138610839844\n",
            "Parameter classifier.1.bias after step: 0.38285622000694275\n",
            "Parameter classifier.4.weight after step: 36.94754409790039\n",
            "Parameter classifier.4.bias after step: 0.577488362789154\n",
            "Parameter classifier.6.weight after step: 5.776336669921875\n",
            "Parameter classifier.6.bias after step: 0.08521901071071625\n",
            "Gradient of features.0.weight: 0.0032534473575651646\n",
            "Gradient of features.0.bias: 0.00020149015472270548\n",
            "Gradient of features.3.weight: 0.007616476155817509\n",
            "Gradient of features.3.bias: 0.0004270404460839927\n",
            "Gradient of features.6.weight: 0.008507829159498215\n",
            "Gradient of features.6.bias: 0.0008828333229757845\n",
            "Gradient of features.8.weight: 0.011390788480639458\n",
            "Gradient of features.8.bias: 0.0020676665008068085\n",
            "Gradient of features.10.weight: 0.008799221366643906\n",
            "Gradient of features.10.bias: 0.005011861212551594\n",
            "Gradient of classifier.1.weight: 0.023585747927427292\n",
            "Gradient of classifier.1.bias: 0.007560307160019875\n",
            "Gradient of classifier.4.weight: 0.016545264050364494\n",
            "Gradient of classifier.4.bias: 0.013585859909653664\n",
            "Gradient of classifier.6.weight: 0.021144889295101166\n",
            "Gradient of classifier.6.bias: 0.03260992094874382\n",
            "Parameter features.0.weight after step: 4.614903450012207\n",
            "Parameter features.0.bias after step: 0.2578955888748169\n",
            "Parameter features.3.weight after step: 7.995477199554443\n",
            "Parameter features.3.bias after step: 0.19868391752243042\n",
            "Parameter features.6.weight after step: 11.308544158935547\n",
            "Parameter features.6.bias after step: 0.2677423059940338\n",
            "Parameter features.8.weight after step: 9.24176025390625\n",
            "Parameter features.8.bias after step: 0.14991119503974915\n",
            "Parameter features.10.weight after step: 9.230460166931152\n",
            "Parameter features.10.bias after step: 0.19636817276477814\n",
            "Parameter classifier.1.weight after step: 36.956138610839844\n",
            "Parameter classifier.1.bias after step: 0.38285624980926514\n",
            "Parameter classifier.4.weight after step: 36.94754409790039\n",
            "Parameter classifier.4.bias after step: 0.5774883031845093\n",
            "Parameter classifier.6.weight after step: 5.776336669921875\n",
            "Parameter classifier.6.bias after step: 0.08522037416696548\n",
            "Gradient of features.0.weight: 0.0030418201349675655\n",
            "Gradient of features.0.bias: 0.0001418938481947407\n",
            "Gradient of features.3.weight: 0.007232219912111759\n",
            "Gradient of features.3.bias: 0.0003729822929017246\n",
            "Gradient of features.6.weight: 0.0073193698190152645\n",
            "Gradient of features.6.bias: 0.0007026649545878172\n",
            "Gradient of features.8.weight: 0.010442640632390976\n",
            "Gradient of features.8.bias: 0.0018410400953143835\n",
            "Gradient of features.10.weight: 0.00830889493227005\n",
            "Gradient of features.10.bias: 0.004521970171481371\n",
            "Gradient of classifier.1.weight: 0.023958446457982063\n",
            "Gradient of classifier.1.bias: 0.007709936238825321\n",
            "Gradient of classifier.4.weight: 0.016759643331170082\n",
            "Gradient of classifier.4.bias: 0.013566287234425545\n",
            "Gradient of classifier.6.weight: 0.02213769033551216\n",
            "Gradient of classifier.6.bias: 0.03414105251431465\n",
            "Parameter features.0.weight after step: 4.614903450012207\n",
            "Parameter features.0.bias after step: 0.25789564847946167\n",
            "Parameter features.3.weight after step: 7.995477199554443\n",
            "Parameter features.3.bias after step: 0.19868388772010803\n",
            "Parameter features.6.weight after step: 11.308544158935547\n",
            "Parameter features.6.bias after step: 0.2677423059940338\n",
            "Parameter features.8.weight after step: 9.24176025390625\n",
            "Parameter features.8.bias after step: 0.14991101622581482\n",
            "Parameter features.10.weight after step: 9.230460166931152\n",
            "Parameter features.10.bias after step: 0.19636856019496918\n",
            "Parameter classifier.1.weight after step: 36.956138610839844\n",
            "Parameter classifier.1.bias after step: 0.3828561007976532\n",
            "Parameter classifier.4.weight after step: 36.947540283203125\n",
            "Parameter classifier.4.bias after step: 0.577488124370575\n",
            "Parameter classifier.6.weight after step: 5.776336669921875\n",
            "Parameter classifier.6.bias after step: 0.08521720767021179\n",
            "Gradient of features.0.weight: 0.003703869180753827\n",
            "Gradient of features.0.bias: 0.00019479847105685622\n",
            "Gradient of features.3.weight: 0.006942350883036852\n",
            "Gradient of features.3.bias: 0.0003636960464064032\n",
            "Gradient of features.6.weight: 0.008007745258510113\n",
            "Gradient of features.6.bias: 0.0008219426963478327\n",
            "Gradient of features.8.weight: 0.010909488424658775\n",
            "Gradient of features.8.bias: 0.0019878430757671595\n",
            "Gradient of features.10.weight: 0.00865673366934061\n",
            "Gradient of features.10.bias: 0.004774477798491716\n",
            "Gradient of classifier.1.weight: 0.0234703216701746\n",
            "Gradient of classifier.1.bias: 0.007453728001564741\n",
            "Gradient of classifier.4.weight: 0.016370326280593872\n",
            "Gradient of classifier.4.bias: 0.01284981518983841\n",
            "Gradient of classifier.6.weight: 0.020851299166679382\n",
            "Gradient of classifier.6.bias: 0.03164731711149216\n",
            "Parameter features.0.weight after step: 4.614903450012207\n",
            "Parameter features.0.bias after step: 0.25789570808410645\n",
            "Parameter features.3.weight after step: 7.995477199554443\n",
            "Parameter features.3.bias after step: 0.19868388772010803\n",
            "Parameter features.6.weight after step: 11.308544158935547\n",
            "Parameter features.6.bias after step: 0.2677423059940338\n",
            "Parameter features.8.weight after step: 9.24176025390625\n",
            "Parameter features.8.bias after step: 0.1499108374118805\n",
            "Parameter features.10.weight after step: 9.230460166931152\n",
            "Parameter features.10.bias after step: 0.19636866450309753\n",
            "Parameter classifier.1.weight after step: 36.956138610839844\n",
            "Parameter classifier.1.bias after step: 0.38285601139068604\n",
            "Parameter classifier.4.weight after step: 36.94754409790039\n",
            "Parameter classifier.4.bias after step: 0.577488124370575\n",
            "Parameter classifier.6.weight after step: 5.776336669921875\n",
            "Parameter classifier.6.bias after step: 0.08521115034818649\n",
            "Gradient of features.0.weight: 0.003217106917873025\n",
            "Gradient of features.0.bias: 0.00016184152627829462\n",
            "Gradient of features.3.weight: 0.007172931917011738\n",
            "Gradient of features.3.bias: 0.00038949496229179204\n",
            "Gradient of features.6.weight: 0.008329099975526333\n",
            "Gradient of features.6.bias: 0.0008672949625179172\n",
            "Gradient of features.8.weight: 0.011776141822338104\n",
            "Gradient of features.8.bias: 0.0021273107267916203\n",
            "Gradient of features.10.weight: 0.009386865422129631\n",
            "Gradient of features.10.bias: 0.0053809513337910175\n",
            "Gradient of classifier.1.weight: 0.023624274879693985\n",
            "Gradient of classifier.1.bias: 0.007476598955690861\n",
            "Gradient of classifier.4.weight: 0.01644134894013405\n",
            "Gradient of classifier.4.bias: 0.012808446772396564\n",
            "Gradient of classifier.6.weight: 0.0209786556661129\n",
            "Gradient of classifier.6.bias: 0.031527433544397354\n",
            "Parameter features.0.weight after step: 4.614903450012207\n",
            "Parameter features.0.bias after step: 0.2578957974910736\n",
            "Parameter features.3.weight after step: 7.995477199554443\n",
            "Parameter features.3.bias after step: 0.19868388772010803\n",
            "Parameter features.6.weight after step: 11.308544158935547\n",
            "Parameter features.6.bias after step: 0.26774242520332336\n",
            "Parameter features.8.weight after step: 9.24176025390625\n",
            "Parameter features.8.bias after step: 0.14991064369678497\n",
            "Parameter features.10.weight after step: 9.230460166931152\n",
            "Parameter features.10.bias after step: 0.19636882841587067\n",
            "Parameter classifier.1.weight after step: 36.956138610839844\n",
            "Parameter classifier.1.bias after step: 0.38285592198371887\n",
            "Parameter classifier.4.weight after step: 36.94754409790039\n",
            "Parameter classifier.4.bias after step: 0.5774880051612854\n",
            "Parameter classifier.6.weight after step: 5.776337146759033\n",
            "Parameter classifier.6.bias after step: 0.0852040946483612\n",
            "Gradient of features.0.weight: 0.003181548323482275\n",
            "Gradient of features.0.bias: 0.00018173099670093507\n",
            "Gradient of features.3.weight: 0.007137163542211056\n",
            "Gradient of features.3.bias: 0.00038947912980802357\n",
            "Gradient of features.6.weight: 0.008012168109416962\n",
            "Gradient of features.6.bias: 0.0008489011670462787\n",
            "Gradient of features.8.weight: 0.010402186773717403\n",
            "Gradient of features.8.bias: 0.0018604511860758066\n",
            "Gradient of features.10.weight: 0.008548672311007977\n",
            "Gradient of features.10.bias: 0.004768135026097298\n",
            "Gradient of classifier.1.weight: 0.023364845663309097\n",
            "Gradient of classifier.1.bias: 0.0073456838726997375\n",
            "Gradient of classifier.4.weight: 0.016209032386541367\n",
            "Gradient of classifier.4.bias: 0.01243776548653841\n",
            "Gradient of classifier.6.weight: 0.02069648541510105\n",
            "Gradient of classifier.6.bias: 0.03099452704191208\n",
            "Parameter features.0.weight after step: 4.614903450012207\n",
            "Parameter features.0.bias after step: 0.25789588689804077\n",
            "Parameter features.3.weight after step: 7.995477199554443\n",
            "Parameter features.3.bias after step: 0.19868388772010803\n",
            "Parameter features.6.weight after step: 11.308544158935547\n",
            "Parameter features.6.bias after step: 0.2677425742149353\n",
            "Parameter features.8.weight after step: 9.24176025390625\n",
            "Parameter features.8.bias after step: 0.14991039037704468\n",
            "Parameter features.10.weight after step: 9.230460166931152\n",
            "Parameter features.10.bias after step: 0.19636890292167664\n",
            "Parameter classifier.1.weight after step: 36.956138610839844\n",
            "Parameter classifier.1.bias after step: 0.3828556537628174\n",
            "Parameter classifier.4.weight after step: 36.94754409790039\n",
            "Parameter classifier.4.bias after step: 0.5774878263473511\n",
            "Parameter classifier.6.weight after step: 5.776336669921875\n",
            "Parameter classifier.6.bias after step: 0.08519715070724487\n",
            "Gradient of features.0.weight: 0.0033903734292834997\n",
            "Gradient of features.0.bias: 0.00014607672346755862\n",
            "Gradient of features.3.weight: 0.00701696053147316\n",
            "Gradient of features.3.bias: 0.0003777872771024704\n",
            "Gradient of features.6.weight: 0.0078219473361969\n",
            "Gradient of features.6.bias: 0.0007853428251110017\n",
            "Gradient of features.8.weight: 0.010893060825765133\n",
            "Gradient of features.8.bias: 0.001939030596986413\n",
            "Gradient of features.10.weight: 0.008741543628275394\n",
            "Gradient of features.10.bias: 0.004957166500389576\n",
            "Gradient of classifier.1.weight: 0.023839833214879036\n",
            "Gradient of classifier.1.bias: 0.007632705848664045\n",
            "Gradient of classifier.4.weight: 0.016704462468624115\n",
            "Gradient of classifier.4.bias: 0.01346850860863924\n",
            "Gradient of classifier.6.weight: 0.02188747748732567\n",
            "Gradient of classifier.6.bias: 0.03352236747741699\n",
            "Parameter features.0.weight after step: 4.614903926849365\n",
            "Parameter features.0.bias after step: 0.2578960061073303\n",
            "Parameter features.3.weight after step: 7.995477199554443\n",
            "Parameter features.3.bias after step: 0.1986839324235916\n",
            "Parameter features.6.weight after step: 11.308544158935547\n",
            "Parameter features.6.bias after step: 0.26774272322654724\n",
            "Parameter features.8.weight after step: 9.24176025390625\n",
            "Parameter features.8.bias after step: 0.14991004765033722\n",
            "Parameter features.10.weight after step: 9.230460166931152\n",
            "Parameter features.10.bias after step: 0.1963682919740677\n",
            "Parameter classifier.1.weight after step: 36.956138610839844\n",
            "Parameter classifier.1.bias after step: 0.38285544514656067\n",
            "Parameter classifier.4.weight after step: 36.94754409790039\n",
            "Parameter classifier.4.bias after step: 0.5774878859519958\n",
            "Parameter classifier.6.weight after step: 5.776336669921875\n",
            "Parameter classifier.6.bias after step: 0.08519161492586136\n",
            "Gradient of features.0.weight: 0.0036056058015674353\n",
            "Gradient of features.0.bias: 0.00018063443712890148\n",
            "Gradient of features.3.weight: 0.007170914206653833\n",
            "Gradient of features.3.bias: 0.0003738964442163706\n",
            "Gradient of features.6.weight: 0.008045182563364506\n",
            "Gradient of features.6.bias: 0.0008466992876492441\n",
            "Gradient of features.8.weight: 0.01162616815418005\n",
            "Gradient of features.8.bias: 0.002205133205279708\n",
            "Gradient of features.10.weight: 0.008990256115794182\n",
            "Gradient of features.10.bias: 0.005082213785499334\n",
            "Gradient of classifier.1.weight: 0.023108897730708122\n",
            "Gradient of classifier.1.bias: 0.007102839648723602\n",
            "Gradient of classifier.4.weight: 0.015904420986771584\n",
            "Gradient of classifier.4.bias: 0.011406113393604755\n",
            "Gradient of classifier.6.weight: 0.018745211884379387\n",
            "Gradient of classifier.6.bias: 0.026339087635278702\n",
            "Parameter features.0.weight after step: 4.614903926849365\n",
            "Parameter features.0.bias after step: 0.2578960955142975\n",
            "Parameter features.3.weight after step: 7.995477199554443\n",
            "Parameter features.3.bias after step: 0.1986839920282364\n",
            "Parameter features.6.weight after step: 11.308544158935547\n",
            "Parameter features.6.bias after step: 0.26774290204048157\n",
            "Parameter features.8.weight after step: 9.24176025390625\n",
            "Parameter features.8.bias after step: 0.1499098390340805\n",
            "Parameter features.10.weight after step: 9.230460166931152\n",
            "Parameter features.10.bias after step: 0.19636783003807068\n",
            "Parameter classifier.1.weight after step: 36.956138610839844\n",
            "Parameter classifier.1.bias after step: 0.3828551471233368\n",
            "Parameter classifier.4.weight after step: 36.94754409790039\n",
            "Parameter classifier.4.bias after step: 0.5774880051612854\n",
            "Parameter classifier.6.weight after step: 5.776337146759033\n",
            "Parameter classifier.6.bias after step: 0.08518972247838974\n",
            "Gradient of features.0.weight: 0.0033591692335903645\n",
            "Gradient of features.0.bias: 0.00021213771833572537\n",
            "Gradient of features.3.weight: 0.007378903217613697\n",
            "Gradient of features.3.bias: 0.0004291258519515395\n",
            "Gradient of features.6.weight: 0.0083958450704813\n",
            "Gradient of features.6.bias: 0.000869134848471731\n",
            "Gradient of features.8.weight: 0.012162596918642521\n",
            "Gradient of features.8.bias: 0.0023287353105843067\n",
            "Gradient of features.10.weight: 0.009681212715804577\n",
            "Gradient of features.10.bias: 0.005622970871627331\n",
            "Gradient of classifier.1.weight: 0.023144260048866272\n",
            "Gradient of classifier.1.bias: 0.0072540114633738995\n",
            "Gradient of classifier.4.weight: 0.01587245799601078\n",
            "Gradient of classifier.4.bias: 0.011616132222115993\n",
            "Gradient of classifier.6.weight: 0.018656235188245773\n",
            "Gradient of classifier.6.bias: 0.026241643354296684\n",
            "Parameter features.0.weight after step: 4.614903926849365\n",
            "Parameter features.0.bias after step: 0.2578961253166199\n",
            "Parameter features.3.weight after step: 7.995477199554443\n",
            "Parameter features.3.bias after step: 0.19868406653404236\n",
            "Parameter features.6.weight after step: 11.308544158935547\n",
            "Parameter features.6.bias after step: 0.26774317026138306\n",
            "Parameter features.8.weight after step: 9.24176025390625\n",
            "Parameter features.8.bias after step: 0.14990967512130737\n",
            "Parameter features.10.weight after step: 9.230460166931152\n",
            "Parameter features.10.bias after step: 0.19636763632297516\n",
            "Parameter classifier.1.weight after step: 36.95614242553711\n",
            "Parameter classifier.1.bias after step: 0.3828548789024353\n",
            "Parameter classifier.4.weight after step: 36.94754409790039\n",
            "Parameter classifier.4.bias after step: 0.5774885416030884\n",
            "Parameter classifier.6.weight after step: 5.776337146759033\n",
            "Parameter classifier.6.bias after step: 0.08518809825181961\n",
            "Gradient of features.0.weight: 0.003476749872788787\n",
            "Gradient of features.0.bias: 0.0001873130677267909\n",
            "Gradient of features.3.weight: 0.007557684555649757\n",
            "Gradient of features.3.bias: 0.00040757222450338304\n",
            "Gradient of features.6.weight: 0.008517512120306492\n",
            "Gradient of features.6.bias: 0.0009182326029986143\n",
            "Gradient of features.8.weight: 0.01159392949193716\n",
            "Gradient of features.8.bias: 0.0022205556742846966\n",
            "Gradient of features.10.weight: 0.0090750427916646\n",
            "Gradient of features.10.bias: 0.00527182687073946\n",
            "Gradient of classifier.1.weight: 0.02344023995101452\n",
            "Gradient of classifier.1.bias: 0.007451888173818588\n",
            "Gradient of classifier.4.weight: 0.016385216265916824\n",
            "Gradient of classifier.4.bias: 0.013086370192468166\n",
            "Gradient of classifier.6.weight: 0.02092602662742138\n",
            "Gradient of classifier.6.bias: 0.03215270861983299\n",
            "Parameter features.0.weight after step: 4.614903926849365\n",
            "Parameter features.0.bias after step: 0.25789618492126465\n",
            "Parameter features.3.weight after step: 7.995477199554443\n",
            "Parameter features.3.bias after step: 0.19868411123752594\n",
            "Parameter features.6.weight after step: 11.308544158935547\n",
            "Parameter features.6.bias after step: 0.26774337887763977\n",
            "Parameter features.8.weight after step: 9.24176025390625\n",
            "Parameter features.8.bias after step: 0.14990948140621185\n",
            "Parameter features.10.weight after step: 9.230460166931152\n",
            "Parameter features.10.bias after step: 0.196367546916008\n",
            "Parameter classifier.1.weight after step: 36.95614242553711\n",
            "Parameter classifier.1.bias after step: 0.3828545808792114\n",
            "Parameter classifier.4.weight after step: 36.94754409790039\n",
            "Parameter classifier.4.bias after step: 0.5774891972541809\n",
            "Parameter classifier.6.weight after step: 5.776337146759033\n",
            "Parameter classifier.6.bias after step: 0.08518319576978683\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-71d5de51b5e7>\u001b[0m in \u001b[0;36m<cell line: 132>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using device: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{model_name}_SGD.pth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{model_name}_SGD.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;31m# Test both checkpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-71d5de51b5e7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, val_loader, num_epochs, checkpoint_epochs, save_file, plot_file)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load CIFAR100 Dataset with fine labels\n",
        "transform = transforms.Compose([transforms.Resize(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize((0.507, 0.487, 0.441), (0.267, 0.256, 0.276))])\n",
        "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Split train into training and validation\n",
        "# train_size = int(0.8 * len(train_dataset))\n",
        "# val_size = len(train_dataset) - train_size\n",
        "# train_data, val_data = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# Define models\n",
        "models_dict = {\n",
        "    'AlexNet': models.alexnet(),\n",
        "    # 'VGG16': models.vgg16(),\n",
        "    # 'ResNet18': models.resnet18()\n",
        "}\n",
        "\n",
        "# Modify the classifiers to output 100 classes for CIFAR100\n",
        "for model_name, model in models_dict.items():\n",
        "    if model_name == 'AlexNet' or model_name == 'VGG16':\n",
        "        model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, 100)\n",
        "    elif model_name == 'ResNet18':\n",
        "        model.fc = nn.Linear(model.fc.in_features, 100)\n",
        "\n",
        "# Training function\n",
        "def train(model, device, train_loader, val_loader, num_epochs, checkpoint_epochs, save_file=None, plot_file=None):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum = 0.9)\n",
        "    train_losses, val_losses = [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        n=0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "             # Less verbose debugging: Print gradients and parameters for the first few batches of the first epoch\n",
        "            if epoch == 0 and n < 5:\n",
        "                for name, param in model.named_parameters():\n",
        "                    if param.grad is not None:\n",
        "                        print(f'Gradient of {name}: {param.grad.norm()}')\n",
        "                    print(f'Parameter {name} after step: {param.norm()}')\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if(n%50 == 0):\n",
        "              print(f\"batch {n} of {len(train_loader)}\")\n",
        "            n+=1\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        train_losses.append(avg_loss)\n",
        "\n",
        "        print(datetime.datetime.now(), 'epoch:', epoch, 'train loss:', avg_loss)\n",
        "\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "        val_avg_loss = val_loss / len(val_loader)\n",
        "        val_losses.append(val_avg_loss)\n",
        "\n",
        "        print(datetime.datetime.now(), 'epoch:', epoch, 'val loss:', val_avg_loss)\n",
        "\n",
        "\n",
        "        if save_file != None:\n",
        "            torch.save(model.state_dict(), save_file)\n",
        "\n",
        "        if plot_file != None:\n",
        "            plt.figure(2, figsize=(12, 7))\n",
        "            plt.clf()\n",
        "            plt.plot(train_losses, label='train')\n",
        "            plt.plot(val_losses, label='val')\n",
        "            plt.xlabel('epoch')\n",
        "            plt.ylabel('loss')\n",
        "            plt.legend(loc=1)\n",
        "            print('saving ', plot_file)\n",
        "            plt.savefig(plot_file)\n",
        "\n",
        "        # Save checkpoint if at a checkpoint epoch\n",
        "        if epoch + 1 in checkpoint_epochs:\n",
        "            torch.save(model.state_dict(), f\"{model_name}_epoch_{epoch+1}.pth\")\n",
        "\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n",
        "# Testing function\n",
        "def test(model, test_loader, top_k):\n",
        "    model.eval()\n",
        "    top1_errors, top5_errors = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, pred_top5 = outputs.topk(5, 1, largest=True, sorted=True)\n",
        "            top1_errors += (pred_top5[:, 0] != labels).sum().item()\n",
        "            top5_errors += (pred_top5 == labels.view(-1, 1)).sum().item()\n",
        "\n",
        "    total_samples = len(test_loader.dataset)\n",
        "    top1_error_rate = top1_errors / total_samples\n",
        "    top5_error_rate = (total_samples - top5_errors) / total_samples\n",
        "    return top1_error_rate, top5_error_rate\n",
        "\n",
        "# Run the process for each model\n",
        "checkpoint_epochs = [5, 50]  # Modify '50' to the desired full convergence epoch count\n",
        "results = {}\n",
        "for model_name, model in models_dict.items():\n",
        "    print(f\"Training {model_name}\")\n",
        "    print('Using device: ', device)\n",
        "    model = model.to(device)\n",
        "    train_losses, val_losses = train(model, device, train_loader, val_loader, num_epochs=50, checkpoint_epochs=checkpoint_epochs, save_file=f\"{model_name}_SGD.pth\", plot_file=f\"{model_name}_SGD.png\")\n",
        "\n",
        "    # Test both checkpoints\n",
        "    for epoch in checkpoint_epochs:\n",
        "        model.load_state_dict(torch.load(f\"{model_name}_epoch_{epoch}.pth\"))\n",
        "        top1, top5 = test(model, test_loader, top_k=5)\n",
        "        results[f\"{model_name}_epoch_{epoch}\"] = {\"top1_error\": top1, \"top5_error\": top5}\n",
        "        print(f\"{model_name} Epoch {epoch} - Top-1 Error: {top1}, Top-5 Error: {top5}\")\n",
        "\n",
        "# Save or print final results\n",
        "print(\"Final results:\", results)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}